{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "841834e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "410254a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lda = pd.read_csv('df_lda.csv')  \n",
    "# combine lda matrix with other engineered features\n",
    "df_selected = pd.read_csv('selected_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "140bce46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.843240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129313</td>\n",
       "      <td>0.023743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.461015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.260180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.390031</td>\n",
       "      <td>0.086231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.531466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.464855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17875</th>\n",
       "      <td>17875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520710</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.476453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17876</th>\n",
       "      <td>17876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.820428</td>\n",
       "      <td>0.057140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17877</th>\n",
       "      <td>17877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.854610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17878</th>\n",
       "      <td>17878</td>\n",
       "      <td>0.448880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.543173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17879</th>\n",
       "      <td>17879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.916355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17880 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0         0         1         2    3         4         5  \\\n",
       "0               0  0.843240  0.000000  0.000000  0.0  0.129313  0.023743   \n",
       "1               1  0.461015  0.000000  0.238566  0.0  0.000000  0.038640   \n",
       "2               2  0.000000  0.390031  0.086231  0.0  0.019531  0.000000   \n",
       "3               3  0.000000  0.000000  0.000000  0.0  0.000000  0.000000   \n",
       "4               4  0.000000  0.531466  0.000000  0.0  0.464855  0.000000   \n",
       "...           ...       ...       ...       ...  ...       ...       ...   \n",
       "17875       17875  0.000000  0.000000  0.000000  0.0  0.000000  0.520710   \n",
       "17876       17876  0.000000  0.118918  0.000000  0.0  0.820428  0.057140   \n",
       "17877       17877  0.000000  0.854610  0.000000  0.0  0.000000  0.000000   \n",
       "17878       17878  0.448880  0.000000  0.000000  0.0  0.000000  0.543173   \n",
       "17879       17879  0.000000  0.000000  0.000000  0.0  0.000000  0.916355   \n",
       "\n",
       "              6         7         8    9        10  \n",
       "0      0.000000  0.000000  0.000000  0.0  0.000000  \n",
       "1      0.000000  0.260180  0.000000  0.0  0.000000  \n",
       "2      0.000000  0.000000  0.500167  0.0  0.000000  \n",
       "3      0.000000  0.000000  0.000000  0.0  0.997938  \n",
       "4      0.000000  0.000000  0.000000  0.0  0.000000  \n",
       "...         ...       ...       ...  ...       ...  \n",
       "17875  0.000000  0.000000  0.000000  0.0  0.476453  \n",
       "17876  0.000000  0.000000  0.000000  0.0  0.000000  \n",
       "17877  0.142097  0.000000  0.000000  0.0  0.000000  \n",
       "17878  0.000000  0.000000  0.000000  0.0  0.000000  \n",
       "17879  0.000000  0.057486  0.000000  0.0  0.024032  \n",
       "\n",
       "[17880 rows x 12 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b5b01b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lda = df_lda.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a3e8cf9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.843240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129313</td>\n",
       "      <td>0.023743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.461015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.260180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.390031</td>\n",
       "      <td>0.086231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.531466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.464855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17875</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520710</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.476453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17876</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.820428</td>\n",
       "      <td>0.057140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17877</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.854610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17878</th>\n",
       "      <td>0.448880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.543173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17879</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.916355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17880 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2    3         4         5         6  \\\n",
       "0      0.843240  0.000000  0.000000  0.0  0.129313  0.023743  0.000000   \n",
       "1      0.461015  0.000000  0.238566  0.0  0.000000  0.038640  0.000000   \n",
       "2      0.000000  0.390031  0.086231  0.0  0.019531  0.000000  0.000000   \n",
       "3      0.000000  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "4      0.000000  0.531466  0.000000  0.0  0.464855  0.000000  0.000000   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "17875  0.000000  0.000000  0.000000  0.0  0.000000  0.520710  0.000000   \n",
       "17876  0.000000  0.118918  0.000000  0.0  0.820428  0.057140  0.000000   \n",
       "17877  0.000000  0.854610  0.000000  0.0  0.000000  0.000000  0.142097   \n",
       "17878  0.448880  0.000000  0.000000  0.0  0.000000  0.543173  0.000000   \n",
       "17879  0.000000  0.000000  0.000000  0.0  0.000000  0.916355  0.000000   \n",
       "\n",
       "              7         8    9        10  \n",
       "0      0.000000  0.000000  0.0  0.000000  \n",
       "1      0.260180  0.000000  0.0  0.000000  \n",
       "2      0.000000  0.500167  0.0  0.000000  \n",
       "3      0.000000  0.000000  0.0  0.997938  \n",
       "4      0.000000  0.000000  0.0  0.000000  \n",
       "...         ...       ...  ...       ...  \n",
       "17875  0.000000  0.000000  0.0  0.476453  \n",
       "17876  0.000000  0.000000  0.0  0.000000  \n",
       "17877  0.000000  0.000000  0.0  0.000000  \n",
       "17878  0.000000  0.000000  0.0  0.000000  \n",
       "17879  0.057486  0.000000  0.0  0.024032  \n",
       "\n",
       "[17880 rows x 11 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "05a74ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_selected,df_lda],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bd1e4cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#  Create an instance of StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to your DataFrame\n",
    "scaler.fit(df_all.drop('fraudulent',axis = 1).values)\n",
    "X_scaled = scaler.transform(df_all.drop('fraudulent',axis = 1).values)\n",
    "df_scaled = pd.DataFrame(X_scaled,columns = df_all.drop('fraudulent',axis = 1).columns)\n",
    "df_scaled['fraudulent'] = df_all['fraudulent'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "71ea9838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12748\n",
       "1      662\n",
       "Name: fraudulent, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(26)\n",
    "# Train_test\n",
    "df_train = df_all.sample(frac = 0.75)\n",
    "df_test = df_all.drop(df_train.index)\n",
    "\n",
    "df_train['fraudulent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "47b3cefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12748\n",
       "1    12578\n",
       "Name: fraudulent, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# oversample the training set to tackle the imbalance\n",
    "def over_sample(data):\n",
    "    #Make a balanced dataset by oversampling\n",
    "    data_Fraud = data[data['fraudulent']==1]\n",
    "    data_NonFraud =  data[data['fraudulent']==0]    \n",
    "    df_fraud_example = pd.concat([data_Fraud, data_Fraud, data_Fraud, data_Fraud, \n",
    "                                  data_Fraud, data_Fraud, data_Fraud, data_Fraud, \n",
    "                                  data_Fraud, data_Fraud, data_Fraud, data_Fraud, \n",
    "                                 data_Fraud, data_Fraud, data_Fraud, data_Fraud, \n",
    "                                 data_Fraud, data_Fraud, data_Fraud], axis = 0)\n",
    "    data_balanced = pd.concat([data_NonFraud, df_fraud_example], axis = 0)\n",
    "    data_balanced = data_balanced.sample(frac=1).reset_index(drop=True)\n",
    "    return data_balanced\n",
    "\n",
    "df_train_bal = over_sample(df_train)\n",
    "df_train_bal['fraudulent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e9147441",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_bal.drop(['fraudulent'], axis=1)\n",
    "y_train = df_train_bal['fraudulent']\n",
    "\n",
    "X_test = df_test.drop(['fraudulent'], axis=1)\n",
    "y_test = df_test['fraudulent']\n",
    "\n",
    "## for machine learning\n",
    "from sklearn import model_selection, preprocessing, feature_selection, ensemble, linear_model, metrics, decomposition\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ae0b3130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['company_profile', 'description', 'requirements', 'benefits',\n",
       "       'telecommuting', 'has_company_logo', 'has_questions', 'money_in_title',\n",
       "       'money_in_desc', 'cons_punc_des', 'cons_punc_title',\n",
       "       'low_required_education', 'has_short_company_profile',\n",
       "       'has_short_requirements', '0', '1', '2', '3', '4', '5', '6', '7', '8',\n",
       "       '9', '10'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddab828",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "775095d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (overall correct predictions): 0.81\n",
      "Auc: 0.89\n",
      "Recall (all 1s predicted right): 0.8\n",
      "Precision (confidence when predicting a 1): 0.82\n",
      "Detail:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81     12748\n",
      "           1       0.82      0.80      0.81     12578\n",
      "\n",
      "    accuracy                           0.81     25326\n",
      "   macro avg       0.81      0.81      0.81     25326\n",
      "weighted avg       0.81      0.81      0.81     25326\n",
      "\n",
      "Accuracy (overall correct predictions): 0.82\n",
      "Auc: 0.87\n",
      "Recall (all 1s predicted right): 0.78\n",
      "Precision (confidence when predicting a 1): 0.17\n",
      "Detail:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.82      0.90      4266\n",
      "           1       0.17      0.78      0.28       204\n",
      "\n",
      "    accuracy                           0.82      4470\n",
      "   macro avg       0.58      0.80      0.59      4470\n",
      "weighted avg       0.95      0.82      0.87      4470\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate a logistic regression model using k-fold cross-validation\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# prepare the cross-validation procedure\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "# create model\n",
    "model = LogisticRegression()\n",
    "# fit model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#train set prediction\n",
    "predicted_prob = model.predict_proba(X_train)[:,1]\n",
    "predicted = model.predict(X_train)\n",
    "## Accuray e AUC\n",
    "accuracy = metrics.accuracy_score(y_train, predicted)\n",
    "auc = metrics.roc_auc_score(y_train, predicted_prob)\n",
    "print(\"Accuracy (overall correct predictions):\",  round(accuracy,2))\n",
    "print(\"Auc:\", round(auc,2))\n",
    "## Precision e Recall\n",
    "recall = metrics.recall_score(y_train, predicted)\n",
    "precision = metrics.precision_score(y_train, predicted)\n",
    "print(\"Recall (all 1s predicted right):\", round(recall,2))\n",
    "print(\"Precision (confidence when predicting a 1):\", round(precision,2))\n",
    "print(\"Detail:\")\n",
    "print(metrics.classification_report(y_train, predicted, target_names=[str(i) for i in np.unique(y_test)]))\n",
    "\n",
    "#test set prediction\n",
    "predicted_prob = model.predict_proba(X_test)[:,1]\n",
    "predicted = model.predict(X_test)\n",
    "## Accuray e AUC\n",
    "accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "auc = metrics.roc_auc_score(y_test, predicted_prob)\n",
    "print(\"Accuracy (overall correct predictions):\",  round(accuracy,2))\n",
    "print(\"Auc:\", round(auc,2))\n",
    "## Precision e Recall\n",
    "recall = metrics.recall_score(y_test, predicted)\n",
    "precision = metrics.precision_score(y_test, predicted)\n",
    "print(\"Recall (all 1s predicted right):\", round(recall,2))\n",
    "print(\"Precision (confidence when predicting a 1):\", round(precision,2))\n",
    "print(\"Detail:\")\n",
    "print(metrics.classification_report(y_test, predicted, target_names=[str(i) for i in np.unique(y_test)]))\n",
    "\n",
    "classes = np.unique(y_test)\n",
    "fig, ax = plt.subplots()\n",
    "cm = metrics.confusion_matrix(y_test, predicted, labels=classes)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap=plt.cm.Blues, cbar=False)\n",
    "ax.set(xlabel=\"Pred\", ylabel=\"True\", title=\"Confusion matrix\")\n",
    "ax.set_yticklabels(labels=classes, rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ffc30b",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "52ec739b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (overall correct predictions): 0.98\n",
      "Auc: 0.97\n",
      "Recall (all 1s predicted right): 0.6\n",
      "Precision (confidence when predicting a 1): 0.85\n",
      "Detail:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      4266\n",
      "           1       0.85      0.60      0.70       204\n",
      "\n",
      "    accuracy                           0.98      4470\n",
      "   macro avg       0.91      0.80      0.84      4470\n",
      "weighted avg       0.97      0.98      0.97      4470\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "## call model\n",
    "rf = RandomForestClassifier(n_estimators = 50, random_state = 26)\n",
    "# fit model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "predicted_prob = rf.predict_proba(X_test)[:,1]\n",
    "rf_predicted = rf.predict(X_test)\n",
    "\n",
    "## Accuray and AUC\n",
    "accuracy = metrics.accuracy_score(y_test, rf_predicted)\n",
    "auc = metrics.roc_auc_score(y_test, predicted_prob)\n",
    "print(\"Accuracy (overall correct predictions):\",  round(accuracy,2))\n",
    "print(\"Auc:\", round(auc,2))\n",
    "    \n",
    "## Precision and Recall\n",
    "recall = metrics.recall_score(y_test, rf_predicted)\n",
    "precision = metrics.precision_score(y_test, rf_predicted)\n",
    "print(\"Recall (all 1s predicted right):\", round(recall,2))\n",
    "print(\"Precision (confidence when predicting a 1):\", round(precision,2))\n",
    "print(\"Detail:\")\n",
    "print(metrics.classification_report(y_test, rf_predicted, target_names=[str(i) for i in np.unique(y_test)]))\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "classes = np.unique(y_test)\n",
    "fig, ax = plt.subplots()\n",
    "cm = metrics.confusion_matrix(y_test, rf_predicted, labels=classes)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap=plt.cm.Blues, cbar=False)\n",
    "ax.set(xlabel=\"Pred\", ylabel=\"True\", title=\"Confusion matrix\")\n",
    "ax.set_yticklabels(labels=classes, rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b68352",
   "metadata": {},
   "source": [
    "# Boosted Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "afaac384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (overall correct predictions): 1.0\n",
      "Auc: 1.0\n",
      "Recall (all 1s predicted right): 1.0\n",
      "Precision (confidence when predicting a 1): 1.0\n",
      "Detail:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12748\n",
      "           1       1.00      1.00      1.00     12578\n",
      "\n",
      "    accuracy                           1.00     25326\n",
      "   macro avg       1.00      1.00      1.00     25326\n",
      "weighted avg       1.00      1.00      1.00     25326\n",
      "\n",
      "Accuracy (overall correct predictions): 0.97\n",
      "Auc: 0.97\n",
      "Recall (all 1s predicted right): 0.73\n",
      "Precision (confidence when predicting a 1): 0.7\n",
      "Detail:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      4266\n",
      "           1       0.70      0.73      0.71       204\n",
      "\n",
      "    accuracy                           0.97      4470\n",
      "   macro avg       0.84      0.86      0.85      4470\n",
      "weighted avg       0.97      0.97      0.97      4470\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAATHUlEQVR4nO3de5SVZb3A8e8PEAVR4jYQGOYF9Rh5QaWjhZqpgYkgctX0aJaaYpl3vCDePdrpZGmZ90xFUTSvS81MTUUDL0dU0LwGIoKAoILJDM/5Y2/GLQ4DOmz28Mz3s1Zr8V7m3b8ZZ33nnWfvPUVKCUlSfppVegBJUnkYeEnKlIGXpEwZeEnKlIGXpEwZeEnKlIHXGikiWkXEXRExPyJuacB1DoiIB1blbJUSEX0i4uVKz6HGI3wdvMopIvYHjgW2AD4AngPOTSk91sDrHggcDeyUUqpu6JyNXUQkoEdK6dVKz6I1h3fwKpuIOBb4NXAe0BnoDvwOGLAKLr8h8EpTiPvKiIgWlZ5BjY+BV1lERFvgLOColNJtKaWPUkqLU0p3pZROKJ6zdkT8OiJmFP/364hYu3hs14iYHhHHRcSsiHgnIg4pHjsTGA0Mi4gPI+LQiBgTEdeXPP7XIyItDV9EHBwRr0fEBxHxRkQcULL/sZKP2ykiJhaXfiZGxE4lxx6OiLMj4vHidR6IiI7L+fyXzn9iyfwDI2KviHglIuZGxCkl5/eOiAkR8X7x3EsiomXx2KPF0/6v+PkOK7n+SRExE7hm6b7ix2xSfIxexe2uEfFeROzakP+uWrMYeJXLjsA6wO31nHMq8J/ANsDWQG/gtJLjXYC2QDfgUODSiGiXUjqDwm8FN6eU2qSUrqpvkIhYF/gN0C+ltB6wE4WlomXPaw/cUzy3A/Ar4J6I6FBy2v7AIUAV0BI4vp6H7kLha9CNwg+kK4AfAtsBfYDREbFx8dwa4BdARwpfu+8BRwKklHYunrN18fO9ueT67Sn8NnNY6QOnlF4DTgJuiIjWwDXAtSmlh+uZV5kx8CqXDsB7K1hCOQA4K6U0K6U0GzgTOLDk+OLi8cUppXuBD4HNv+Q8S4CeEdEqpfROSunFOs75AfDPlNKfUkrVKaWxwFSgf8k516SUXkkpLQLGUfjhtDyLKTzfsBi4iUK8L04pfVB8/BeBrQBSSk+nlJ4sPu6bwB+AXVbiczojpfTv4jyfkVK6Avgn8BTwVQo/UNWEGHiVyxyg4wrWhrsCb5Vsv1XcV3uNZX5ALATafNFBUkofAcOAI4B3IuKeiNhiJeZZOlO3ku2ZX2CeOSmlmuK/lwb43ZLji5Z+fERsFhF3R8TMiFhA4TeUOpd/SsxOKX28gnOuAHoCv00p/XsF5yozBl7lMgH4GBhYzzkzKCwvLNW9uO/L+AhoXbLdpfRgSun+lNIeFO5kp1II34rmWTrT219ypi/i9xTm6pFSWh84BYgVfEy9L4GLiDYUnuS+ChhTXIJSE2LgVRYppfkU1p0vLT652Doi1oqIfhFxYfG0scBpEdGp+GTlaOD65V1zBZ4Ddo6I7sUneEctPRARnSNin+Ja/L8pLPXU1HGNe4HNImL/iGgREcOALYG7v+RMX8R6wALgw+JvFz9d5vi7wMaf+6j6XQw8nVL6MYXnFi5r8JRaoxh4lU1K6VcUXgN/GjAbmAaMBP5cPOUcYBLwPDAZeKa478s81l+Am4vXeprPRrkZcByFO/S5FNa2j6zjGnOAvYvnzgFOBPZOKb33ZWb6go6n8ATuBxR+u7h5meNjgD8WX2UzdEUXi4gBQF8Ky1JQ+O/Qa+mrh9Q0+EYnScqUd/CSlCkDL0mZMvCSlCkDL0mZalR/oKjVtiN9xleN0ryJl1R6BKlO67RY/vslvIOXpEwZeEnKlIGXpEwZeEnKlIGXpEwZeEnKlIGXpEwZeEnKlIGXpEwZeEnKlIGXpEwZeEnKlIGXpEwZeEnKlIGXpEwZeEnKlIGXpEwZeEnKlIGXpEwZeEnKlIGXpEwZeEnKlIGXpEwZeEnKlIGXpEwZeEnKlIGXpEwZeEnKlIGXpEwZeEnKlIGXpEwZeEnKlIGXpEwZeEnKlIGXpEwZeEnKlIGXpEwZeEnKlIGXpEwZeEnKlIGXpEwZeEnKlIGXpEwZeEnKlIGXpEwZeEnKlIGXpEwZeEnKlIGXpEwZeEnKVItyXjwi+gIXA82BK1NKF5Tz8ZqCZs2Cx284kRmz5rPfzy/jvGMGstfOPflkcQ1vTH+Pw864nvkfLgLg+B/tycEDdqRmyRKOu/BWHpwwBYAxR/XngL1785X1W9Pp28dV8tNRE7BgwQLOHH0ar776ChHBmWefxxOPP8b4W8fRvl17AI4+5lj67LxLhSfNT9nu4COiOXAp0A/YEhgREVuW6/GaipH7f5eX33i3dvuvT05luyHn0XvY+fzzrVmc8KM9Adhi4y4M+X4veg0+l32O+h0XjxpKs2YBwL2PTqbPgRdVZH41PReefy7f/k4f7rj7Pm4ZfwcbbbwJAAcedDDjbruDcbfdYdzLpJxLNL2BV1NKr6eUPgFuAgaU8fGy163qK/T9zje45vYnavf99cmp1NQsAeAfk9+gW+evALD3rltxy/3P8Mniat6aMYfXpr3HDj2/XjzvTWa+t2B1j68m6MMPP+Tppyey736DAVirZUvWX3/9Ck/VdJQz8N2AaSXb04v79CVddMJ+nHrxn1myJNV5/KABO3L/4y8B0K1TW6bPnFd77O1Z8+ha1Xa1zCktNX3aNNq1a8/oU0cxdL+BjBl9KgsXLgTgphtvYPC+/Rl92igWzJ9f4UnzVM7ARx37PlemiDgsIiZFxKTq914s4zhrtn59ejJr7gc8O2VancdPPPT71NQs4aZ7JxZ2xOe//KnunwtS2dTUVDN1yksMGT6CceP/TKtWrbj6yssZOmwEd9/3F8aNv4NOnar45UU+PVcO5Qz8dOBrJdsbADOWPSmldHlKafuU0vYtOn6jjOOs2XbcZmP23uWbTL3nTK674BB23WEzrj7nIAAO6P8t9tq5Jwefem3t+W/Pep8NurSr3e5W1Y53ZnuXpNWrc+cudO7cha222hqAPfbsy9QpL9GhY0eaN29Os2bNGDR4CC9MnlzhSfNUzsBPBHpExEYR0RIYDtxZxsfL2ujf3smmfU9nix+cwUEnX8PDE1/hR6ddxx47/QfHHbw7g4/5A4s+Xlx7/j0PP8+Q7/ei5Vot2LBrBzbt3omJL7xZuU9ATVLHTp3o3KULb77xOgBPPTmBjTfZhNmzZ9We89CDD7Jpjx6VGjFrZXuZZEqpOiJGAvdTeJnk1Skl12BWsf89aShrt2zB3b8fCRSeQP3ZuTcx5fWZjH/gWZ4dfyrVNUs45oJxtWv35/58AMP6bU/rddbi1fvO5prbJ3DuH+6t5KehjJ18yumMOul4Fi9ezAYbfI2zzjmfC84/h5enTiUCunbtxuljzqr0mFmK1IgWZlttO7LxDCOVmDfxkkqPINVpnRZ1Pt8J+E5WScqWgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTK0w8FHww4gYXdzuHhG9yz+aJKkhVuYO/nfAjsCI4vYHwKVlm0iStEq0WIlzvpVS6hURzwKklOZFRMsyzyVJaqCVuYNfHBHNgQQQEZ2AJWWdSpLUYCsT+N8AtwNVEXEu8BhwXlmnkiQ12AqXaFJKN0TE08D3gAAGppSmlH0ySVKDrDDwEdEdWAjcVbovpfSvcg4mSWqYlXmS9R4K6+8BrANsBLwMfKOMc0mSGmhllmi+WbodEb2Aw8s2kSRplYiU0hf/oIhnUkq9VvUwH1fzxYeRVoPqGr811Ti1WTtiecdWZg3+2JLNZkAvYPYqmEuSVEYrswa/Xsm/qymsyY8vzziSpFWl3sAX3+DUJqV0wmqaR5K0iiz3jU4R0SKlVENhSUaStIap7w7+HxTi/lxE3AncAny09GBK6bYyzyZJaoCVWYNvD8wBduPT18MnwMBLUiNWX+Criq+geYFPw76UrxmTpEauvsA3B9rw2bAvZeAlqZFb7hudyvVmpvr4Ric1Vr7RSY1VfW90qu/PBS/3gyRJjV99gf/eaptCkrTKLTfwKaW5q3MQSdKqtTL/j06SpDWQgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScpU2QIfEVdHxKyIeKFcj6FP9dtjN/Yb2J+hgwYwYuggAH5/6W/Z/bt9GDpoAEMHDeDvjz5S4SnVFJw5+hR232Unhu7b/3PHrrv2KrbbagvmzZsHwOLFnzDm9FEMHdSf4YMHMGniU6t73Ky1KOO1rwUuAa4r42OoxJXX/JF27dp/Zt+BBx3Mfx1yaIUmUlPUf599GTr8AM449eTP7J858x2eevIJuny1a+2+28ffAsC42+5i7pw5HH3kT/jT2Ftp1szFhVWhbF/FlNKjwNxyXV9S49Rr+x1o27bt5/b/6sLz+fkvTiDi032vv/Yavb+1IwDtO3RgvfXW56UX/aV/VfHHZC4CjvjJoQwfMohbx91cu/umG29g8L79GX3aKBbMn1/BAdWUPfK3h+hU1ZnNNt/iM/s323xzHv7bX6murubt6dOZMuVF3p35ToWmzE/FAx8Rh0XEpIiYdNUVl1d6nDXWH68fy8233s6ll13BzWNv4OlJExk6bAR33/cXxo2/g06dqvjlRRdUekw1QYsWLeKqKy7jiKN+9rlj+wzcj86du3DgiMH8z4XnsfXW29K8RTlXjpuWin8lU0qXA5cDfFxNqvA4a6yqqs4AdOjQgd1234MXJj/PdtvvUHt80OAhHH3kEZUaT03Y9Gn/Ysbb0xkxZAAAs959lwOGDeK6G8fRsWMnjjtxVO25hxw4nO7dN6zUqNmpeODVcAsXLiSlJay7bhsWLlzIhCce5/AjjmT27Fl06lQFwEMPPsimPXpUeFI1RT0225wHH3midnvvvrvxp7HjadeuHYsWLYKUaNW6NU9OeJzmzVuw8SabVnDavJQt8BExFtgV6BgR04EzUkpXlevxmrK5c+bwi58dBUB1TQ17/WBvvt1nZ045+QRenjqVCOjatRunjzmrwpOqKTjlxGOZNGki778/j36778LhRx7NwEGD6zx33tw5jDzix0SzZlRVdebs8/57NU+bt0ip8ayKuESjxqq6xm9NNU5t1i59XdJnVfxJVklSeRh4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScqUgZekTBl4ScpUpJQqPYPKICIOSyldXuk5pLr4/bl6eAefr8MqPYBUD78/VwMDL0mZMvCSlCkDny/XN9WY+f25GvgkqyRlyjt4ScqUgZekTBn4DEVE34h4OSJejYiTKz2PtFREXB0RsyLihUrP0hQY+MxERHPgUqAfsCUwIiK2rOxUUq1rgb6VHqKpMPD56Q28mlJ6PaX0CXATMKDCM0kApJQeBeZWeo6mwsDnpxswrWR7enGfpCbGwOcn6tjna2GlJsjA52c68LWS7Q2AGRWaRVIFGfj8TAR6RMRGEdESGA7cWeGZJFWAgc9MSqkaGAncD0wBxqWUXqzsVFJBRIwFJgCbR8T0iDi00jPlzD9VIEmZ8g5ekjJl4CUpUwZekjJl4CUpUwZekjJl4NWkRURNRDwXES9ExC0R0boB17o2IgavyvmkhjDwauoWpZS2SSn1BD4Bjig9WPzrnNIaycBLn/o7sGlE7BoRf4uIG4HJEdE8Ii6KiIkR8XxEHA4QBZdExEsRcQ9QVdHppWW0qPQAUmMQES0o/A39+4q7egM9U0pvRMRhwPyU0g4RsTbweEQ8AGwLbA58E+gMvARcvfqnl+pm4NXUtYqI54r//jtwFbAT8I+U0hvF/XsCW5Wsr7cFegA7A2NTSjXAjIh4aPWNLa2YgVdTtyiltE3pjogA+Kh0F3B0Sun+Zc7bC/8Usxox1+ClFbsf+GlErAUQEZtFxLrAo8Dw4hr9V4HvVnJIaVnewUsrdiXwdeCZKNzezwYGArcDuwGTgVeARyo0n1Qn/5qkJGXKJRpJypSBl6RMGXhJypSBl6RMGXhJypSBl6RMGXhJytT/A2Q5ozfUKit6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## call model\n",
    "GB = ensemble.GradientBoostingClassifier(max_depth=10, random_state=26)\n",
    "GB.fit(X_train, y_train)\n",
    "\n",
    "#train set prediction\n",
    "predicted_prob = GB.predict_proba(X_train)[:,1]\n",
    "predicted = GB.predict(X_train)\n",
    "## Accuray e AUC\n",
    "accuracy = metrics.accuracy_score(y_train, predicted)\n",
    "auc = metrics.roc_auc_score(y_train, predicted_prob)\n",
    "print(\"Accuracy (overall correct predictions):\",  round(accuracy,2))\n",
    "print(\"Auc:\", round(auc,2))\n",
    "## Precision e Recall\n",
    "recall = metrics.recall_score(y_train, predicted)\n",
    "precision = metrics.precision_score(y_train, predicted)\n",
    "print(\"Recall (all 1s predicted right):\", round(recall,2))\n",
    "print(\"Precision (confidence when predicting a 1):\", round(precision,2))\n",
    "print(\"Detail:\")\n",
    "print(metrics.classification_report(y_train, predicted, target_names=[str(i) for i in np.unique(y_test)]))\n",
    "\n",
    "#test set prediction\n",
    "predicted_prob = GB.predict_proba(X_test)[:,1]\n",
    "predicted = GB.predict(X_test)\n",
    "## Accuray e AUC\n",
    "accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "auc = metrics.roc_auc_score(y_test, predicted_prob)\n",
    "print(\"Accuracy (overall correct predictions):\",  round(accuracy,2))\n",
    "print(\"Auc:\", round(auc,2))\n",
    "## Precision e Recall\n",
    "recall = metrics.recall_score(y_test, predicted)\n",
    "precision = metrics.precision_score(y_test, predicted)\n",
    "print(\"Recall (all 1s predicted right):\", round(recall,2))\n",
    "print(\"Precision (confidence when predicting a 1):\", round(precision,2))\n",
    "print(\"Detail:\")\n",
    "print(metrics.classification_report(y_test, predicted, target_names=[str(i) for i in np.unique(y_test)]))\n",
    "\n",
    "classes = np.unique(y_test)\n",
    "fig, ax = plt.subplots()\n",
    "cm = metrics.confusion_matrix(y_test, predicted, labels=classes)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap=plt.cm.Blues, cbar=False)\n",
    "ax.set(xlabel=\"Pred\", ylabel=\"True\", title=\"Confusion matrix\")\n",
    "ax.set_yticklabels(labels=classes, rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461e1454",
   "metadata": {},
   "source": [
    "# Explainable AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7f0fb491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fc70bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 3062/4470 [03:11<01:25, 16.49it/s]"
     ]
    }
   ],
   "source": [
    "# Fits the explainer\n",
    "explainer = shap.Explainer(GB.predict, X_test)\n",
    "# Calculates the SHAP values - It takes some time\n",
    "shap_values = explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb14b2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63214a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values, max_display=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9d42ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values, max_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d695343",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values, max_display=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3287ab1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
